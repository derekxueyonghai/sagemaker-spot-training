{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Training and using checkpointing on SageMaker Managed Spot Training\n",
    "The example here is almost the same as [PyTorch Cifar10 local training](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/pytorch_cnn_cifar10/pytorch_local_mode_cifar10.ipynb).\n",
    "\n",
    "This notebook tackles the exact same problem with the same solution, but it has been modified to be able to run using SageMaker Managed Spot infrastructure. SageMaker Managed Spot uses [EC2 Spot Instances](https://aws.amazon.com/ec2/spot/) to run Training at a lower cost.\n",
    "\n",
    "Please read the original notebook and try it out to gain an understanding of the ML use-case and how it is being solved. We will not delve into that here in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow, MXNet, PyTorch and Chainer. This tutorial focuses on how to create a convolutional neural network model to train the [Cifar10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) using **PyTorch in local mode**.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "This notebook was created and tested on a single `ml.p2.xlarge` notebook instance.\n",
    "\n",
    "Note: I used `ml.g4dn.xlarge`\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.154.0\n",
      "Checkpointing Path: s3://sagemaker-us-west-2-075912829265/checkpoint-0d4a68fa\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import uuid\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "print('SageMaker version: ' + sagemaker.__version__)\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-cnn-cifar10'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "checkpoint_s3_path = 's3://{}/checkpoint-{}'.format(bucket, checkpoint_suffix)\n",
    "\n",
    "print('Checkpointing Path: {}'.format(checkpoint_s3_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 12 13:23:20 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   38C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "if subprocess.call('nvidia-smi') == 0:\n",
    "    ## Set type to GPU if one is present\n",
    "    instance_type = 'local_gpu'\n",
    "    \n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-12 13:25:14--  https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-managed-spot-training/main/pytorch_managed_spot_training_checkpointing/utils_cifar.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1222 (1.2K) [text/plain]\n",
      "Saving to: ‘utils_cifar.py’\n",
      "\n",
      "utils_cifar.py      100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-10-12 13:25:14 (51.0 MB/s) - ‘utils_cifar.py’ saved [1222/1222]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a utils_cifar.py\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "def _get_transform():\n",
    "    return transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "\n",
    "def get_train_data_loader():\n",
    "    transform = _get_transform()\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    return torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    \n",
    "def get_test_data_loader():\n",
    "    transform = _get_transform()\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    return torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "    \n",
    "\n",
    "# function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:06<00:00, 27570222.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils_cifar import get_train_data_loader, get_test_data_loader, imshow, classes\n",
    "\n",
    "trainloader = get_train_data_loader()\n",
    "testloader = get_test_data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dog     truck       car       cat\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision, torch\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%9s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', bucket=bucket, key_prefix='data/cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for training \n",
    "Here is the full code for the network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir ./source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./source_dir/cifar10.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a ./source_dir/cifar10.py\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision\n",
    "import torchvision.models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "# https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py#L118\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def _train(args):\n",
    "    is_distributed = len(args.hosts) > 1 and args.dist_backend is not None\n",
    "    logger.debug(\"Distributed training - {}\".format(is_distributed))\n",
    "\n",
    "    if os.path.isdir(args.checkpoint_path):\n",
    "        print(\"Checkpointing directory {} exists\".format(args.checkpoint_path))\n",
    "    else:\n",
    "        print(\"Creating Checkpointing directory {}\".format(args.checkpoint_path))\n",
    "        os.mkdir(args.checkpoint_path)\n",
    "    \n",
    "    if is_distributed:\n",
    "        # Initialize the distributed environment.\n",
    "        world_size = len(args.hosts)\n",
    "        os.environ['WORLD_SIZE'] = str(world_size)\n",
    "        host_rank = args.hosts.index(args.current_host)\n",
    "        os.environ['RANK'] = str(host_rank)\n",
    "        dist.init_process_group(backend=args.dist_backend, rank=host_rank, world_size=world_size)\n",
    "        print(\n",
    "            'Initialized the distributed environment: \\'{}\\' backend on {} nodes. '.format(\n",
    "                args.dist_backend,\n",
    "                dist.get_world_size()) + 'Current host rank is {}. Using cuda: {}. Number of gpus: {}'.format(\n",
    "                dist.get_rank(), torch.cuda.is_available(), args.num_gpus))\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"Device Type: {}\".format(device))\n",
    "\n",
    "    print(\"Loading Cifar10 dataset\")\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root=args.data_dir, train=True,\n",
    "                                            download=False, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size,\n",
    "                                               shuffle=True, num_workers=args.workers)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root=args.data_dir, train=False,\n",
    "                                           download=False, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size,\n",
    "                                              shuffle=False, num_workers=args.workers)\n",
    "\n",
    "    print(\"Model loaded\")\n",
    "    model = Net()\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Gpu count: {}\".format(torch.cuda.device_count()))\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    # Check if checkpoints exists\n",
    "    if not os.path.isfile(args.checkpoint_path + '/checkpoint.pth'):\n",
    "        epoch_number = 0\n",
    "    else:    \n",
    "        model, optimizer, epoch_number = _load_checkpoint(model, optimizer, args)        \n",
    "    \n",
    "    for epoch in range(epoch_number, args.epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "            \n",
    "        _save_checkpoint(model, optimizer, epoch, loss, args)\n",
    "            \n",
    "    print('Finished Training')\n",
    "    return _save_model(model, args.model_dir)\n",
    "\n",
    "\n",
    "def _save_model(model, model_dir):\n",
    "    print(\"Saving the model.\")\n",
    "    path = os.path.join(model_dir, 'model.pth')\n",
    "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
    "    torch.save(model.cpu().state_dict(), path)\n",
    "\n",
    "\n",
    "def _save_checkpoint(model, optimizer, epoch, loss, args):\n",
    "    print(\"epoch: {} - loss: {}\".format(epoch+1, loss))\n",
    "    checkpointing_path = args.checkpoint_path + '/checkpoint.pth'\n",
    "    print(\"Saving the Checkpoint: {}\".format(checkpointing_path))\n",
    "    torch.save({\n",
    "        'epoch': epoch+1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        }, checkpointing_path)\n",
    "\n",
    "    \n",
    "def _load_checkpoint(model, optimizer, args):\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Checkpoint file found!\")\n",
    "    print(\"Loading Checkpoint From: {}\".format(args.checkpoint_path + '/checkpoint.pth'))\n",
    "    checkpoint = torch.load(args.checkpoint_path + '/checkpoint.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch_number = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(\"Checkpoint File Loaded - epoch_number: {} - loss: {}\".format(epoch_number, loss))\n",
    "    print('Resuming training from epoch: {}'.format(epoch_number+1))\n",
    "    print(\"--------------------------------------------\")\n",
    "    return model, optimizer, epoch_number\n",
    "\n",
    "    \n",
    "def model_fn(model_dir):\n",
    "    print('model_fn')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = Net()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Gpu count: {}\".format(torch.cuda.device_count()))\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--workers', type=int, default=2, metavar='W',\n",
    "                        help='number of data loading workers (default: 2)')\n",
    "    parser.add_argument('--epochs', type=int, default=2, metavar='E',\n",
    "                        help='number of total epochs to run (default: 2)')\n",
    "    parser.add_argument('--batch_size', type=int, default=4, metavar='BS',\n",
    "                        help='batch size (default: 4)')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                        help='initial learning rate (default: 0.001)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M', help='momentum (default: 0.9)')\n",
    "    parser.add_argument('--dist_backend', type=str, default='gloo', help='distributed backend (default: gloo)')\n",
    "\n",
    "    parser.add_argument('--hosts', type=list, default=json.loads(os.environ['SM_HOSTS']))\n",
    "    parser.add_argument('--current-host', type=str, default=os.environ['SM_CURRENT_HOST'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--data-dir', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "    parser.add_argument(\"--checkpoint-path\",type=str,default=\"/opt/ml/checkpoints\")\n",
    "    parser.add_argument('--num-gpus', type=int, default=os.environ['SM_NUM_GPUS'])\n",
    "\n",
    "    _train(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mparallel\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtransforms\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtransforms\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "logger.setLevel(logging.DEBUG)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "classes = (\u001b[33m'\u001b[39;49;00m\u001b[33mplane\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcar\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mbird\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mdeer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mdog\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfrog\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mhorse\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mship\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtruck\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py#L118\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mNet\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m(Net, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = nn.Conv2d(\u001b[34m3\u001b[39;49;00m, \u001b[34m6\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.pool = nn.MaxPool2d(\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = nn.Conv2d(\u001b[34m6\u001b[39;49;00m, \u001b[34m16\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(\u001b[34m16\u001b[39;49;00m * \u001b[34m5\u001b[39;49;00m * \u001b[34m5\u001b[39;49;00m, \u001b[34m120\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m120\u001b[39;49;00m, \u001b[34m84\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc3 = nn.Linear(\u001b[34m84\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.pool(F.relu(\u001b[36mself\u001b[39;49;00m.conv1(x)))\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.pool(F.relu(\u001b[36mself\u001b[39;49;00m.conv2(x)))\u001b[37m\u001b[39;49;00m\n",
      "        x = x.view(-\u001b[34m1\u001b[39;49;00m, \u001b[34m16\u001b[39;49;00m * \u001b[34m5\u001b[39;49;00m * \u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x))\u001b[37m\u001b[39;49;00m\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc2(x))\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc3(x)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m x\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_train\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\n",
      "    is_distributed = \u001b[36mlen\u001b[39;49;00m(args.hosts) > \u001b[34m1\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.dist_backend \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mDistributed training - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(is_distributed))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m os.path.isdir(args.checkpoint_path):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCheckpointing directory \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m exists\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.checkpoint_path))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCreating Checkpointing directory \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.checkpoint_path))\u001b[37m\u001b[39;49;00m\n",
      "        os.mkdir(args.checkpoint_path)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Initialize the distributed environment.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        world_size = \u001b[36mlen\u001b[39;49;00m(args.hosts)\u001b[37m\u001b[39;49;00m\n",
      "        os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mWORLD_SIZE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(world_size)\u001b[37m\u001b[39;49;00m\n",
      "        host_rank = args.hosts.index(args.current_host)\u001b[37m\u001b[39;49;00m\n",
      "        os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mRANK\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(host_rank)\u001b[37m\u001b[39;49;00m\n",
      "        dist.init_process_group(backend=args.dist_backend, rank=host_rank, world_size=world_size)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mInitialized the distributed environment: \u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33m backend on \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m nodes. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\n",
      "                args.dist_backend,\u001b[37m\u001b[39;49;00m\n",
      "                dist.get_world_size()) + \u001b[33m'\u001b[39;49;00m\u001b[33mCurrent host rank is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m. Using cuda: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m. Number of gpus: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\n",
      "                dist.get_rank(), torch.cuda.is_available(), args.num_gpus))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    device = \u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDevice Type: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(device))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading Cifar10 dataset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    transform = transforms.Compose(\u001b[37m\u001b[39;49;00m\n",
      "        [transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "         transforms.Normalize((\u001b[34m0.5\u001b[39;49;00m, \u001b[34m0.5\u001b[39;49;00m, \u001b[34m0.5\u001b[39;49;00m), (\u001b[34m0.5\u001b[39;49;00m, \u001b[34m0.5\u001b[39;49;00m, \u001b[34m0.5\u001b[39;49;00m))])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    trainset = torchvision.datasets.CIFAR10(root=args.data_dir, train=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                                            download=\u001b[34mFalse\u001b[39;49;00m, transform=transform)\u001b[37m\u001b[39;49;00m\n",
      "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size,\u001b[37m\u001b[39;49;00m\n",
      "                                               shuffle=\u001b[34mTrue\u001b[39;49;00m, num_workers=args.workers)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    testset = torchvision.datasets.CIFAR10(root=args.data_dir, train=\u001b[34mFalse\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                                           download=\u001b[34mFalse\u001b[39;49;00m, transform=transform)\u001b[37m\u001b[39;49;00m\n",
      "    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size,\u001b[37m\u001b[39;49;00m\n",
      "                                              shuffle=\u001b[34mFalse\u001b[39;49;00m, num_workers=args.workers)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mModel loaded\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model = Net()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.device_count() > \u001b[34m1\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGpu count: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(torch.cuda.device_count()))\u001b[37m\u001b[39;49;00m\n",
      "        model = nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model = model.to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    criterion = nn.CrossEntropyLoss().to(device)\u001b[37m\u001b[39;49;00m\n",
      "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Check if checkpoints exists\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.isfile(args.checkpoint_path + \u001b[33m'\u001b[39;49;00m\u001b[33m/checkpoint.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        epoch_number = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:    \u001b[37m\u001b[39;49;00m\n",
      "        model, optimizer, epoch_number = _load_checkpoint(model, optimizer, args)        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(epoch_number, args.epochs):\u001b[37m\u001b[39;49;00m\n",
      "        running_loss = \u001b[34m0.0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m i, data \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# get the inputs\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            inputs, labels = data\u001b[37m\u001b[39;49;00m\n",
      "            inputs, labels = inputs.to(device), labels.to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# zero the parameter gradients\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.zero_grad()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# forward + backward + optimize\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            outputs = model(inputs)\u001b[37m\u001b[39;49;00m\n",
      "            loss = criterion(outputs, labels)\u001b[37m\u001b[39;49;00m\n",
      "            loss.backward()\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.step()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# print statistics\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            running_loss += loss.item()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m i % \u001b[34m2000\u001b[39;49;00m == \u001b[34m1999\u001b[39;49;00m:  \u001b[37m# print every 2000 mini-batches\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m[\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m%5d\u001b[39;49;00m\u001b[33m] loss: \u001b[39;49;00m\u001b[33m%.3f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m %\u001b[37m\u001b[39;49;00m\n",
      "                      (epoch + \u001b[34m1\u001b[39;49;00m, i + \u001b[34m1\u001b[39;49;00m, running_loss / \u001b[34m2000\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "                running_loss = \u001b[34m0.0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "        _save_checkpoint(model, optimizer, epoch, loss, args)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mFinished Training\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m _save_model(model, args.model_dir)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_save_model\u001b[39;49;00m(model, model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# recommended way from http://pytorch.org/docs/master/notes/serialization.html\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_save_checkpoint\u001b[39;49;00m(model, optimizer, epoch, loss, args):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mepoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m - loss: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch+\u001b[34m1\u001b[39;49;00m, loss))\u001b[37m\u001b[39;49;00m\n",
      "    checkpointing_path = args.checkpoint_path + \u001b[33m'\u001b[39;49;00m\u001b[33m/checkpoint.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the Checkpoint: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(checkpointing_path))\u001b[37m\u001b[39;49;00m\n",
      "    torch.save({\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: epoch+\u001b[34m1\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_state_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.state_dict(),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33moptimizer_state_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: optimizer.state_dict(),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mloss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: loss,\u001b[37m\u001b[39;49;00m\n",
      "        }, checkpointing_path)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_checkpoint\u001b[39;49;00m(model, optimizer, args):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m--------------------------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCheckpoint file found!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading Checkpoint From: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.checkpoint_path + \u001b[33m'\u001b[39;49;00m\u001b[33m/checkpoint.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    checkpoint = torch.load(args.checkpoint_path + \u001b[33m'\u001b[39;49;00m\u001b[33m/checkpoint.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model.load_state_dict(checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mmodel_state_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    optimizer.load_state_dict(checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33moptimizer_state_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    epoch_number = checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    loss = checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mloss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCheckpoint File Loaded - epoch_number: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m - loss: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch_number, loss))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mResuming training from epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(epoch_number+\u001b[34m1\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m--------------------------------------------\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model, optimizer, epoch_number\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mmodel_fn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    device = \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model = Net()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.device_count() > \u001b[34m1\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGpu count: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(torch.cuda.device_count()))\u001b[37m\u001b[39;49;00m\n",
      "        model = nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\n",
      "        model.load_state_dict(torch.load(f))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--workers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mW\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of data loading workers (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of total epochs to run (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m4\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mBS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mbatch size (default: 4)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.001\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minitial learning rate (default: 0.001)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.9\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, help=\u001b[33m'\u001b[39;49;00m\u001b[33mmomentum (default: 0.9)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dist_backend\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mgloo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, help=\u001b[33m'\u001b[39;49;00m\u001b[33mdistributed backend (default: gloo)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--checkpoint-path\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,default=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/checkpoints\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    _train(parser.parse_args())\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_dir/cifar10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Functions\n",
    "\n",
    "SageMaker invokes the main function defined within your training script for training. When deploying your trained model to an endpoint, the model_fn() is called to determine how to load your trained model. The model_fn() along with a few other functions list below are called to enable predictions on SageMaker.\n",
    "\n",
    "### [Predicting Functions](https://github.com/aws/sagemaker-pytorch-containers/blob/master/src/sagemaker_pytorch_container/serving.py)\n",
    "* model_fn(model_dir) - loads your model.\n",
    "* input_fn(serialized_input_data, content_type) - deserializes predictions to predict_fn.\n",
    "* output_fn(prediction_output, accept) - serializes predictions from predict_fn.\n",
    "* predict_fn(input_data, model) - calls a model on data deserialized in input_fn.\n",
    "\n",
    "The model_fn() is the only function that doesn't have a default implementation and is required by the user for using PyTorch on SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.PyTorch estimator\n",
    "\n",
    "The `PyTorch` class allows us to run our training function on SageMaker. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. For local training with GPU, we could set this to \"local_gpu\".  In this case, `instance_type` was set above based on your whether you're running a GPU instance.\n",
    "\n",
    "After we've constructed our `PyTorch` object, we fit it using the data we uploaded to S3. Even though we're in local mode, using S3 as our data source makes sense because it maintains consistency with how SageMaker's distributed, managed training ingests data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: yum: not found\n"
     ]
    }
   ],
   "source": [
    "!yum update -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "E: Unable to locate package docker-compose-plugin\n"
     ]
    }
   ],
   "source": [
    "!apt-get install docker-compose-plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-10-12-13-37-38-406\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'docker-compose' is not installed. Local Mode features will not work without docker-compose. For more information on how to install 'docker-compose', please, see https://docs.docker.com/compose/install/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[1;32m      5\u001b[0m cifar10_estimator \u001b[38;5;241m=\u001b[39m PyTorch(entry_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_dir/cifar10.py\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                             role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[1;32m      7\u001b[0m                             framework_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.7.1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                             instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     11\u001b[0m                             instance_type\u001b[38;5;241m=\u001b[39minstance_type)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mcifar10_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:284\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/estimator.py:1195\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_training(job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[1;32m   1194\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[0;32m-> 1195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m \u001b[43m_TrainingJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/estimator.py:2131\u001b[0m, in \u001b[0;36m_TrainingJob.start_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   2106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new Amazon SageMaker training job from the estimator.\u001b[39;00m\n\u001b[1;32m   2107\u001b[0m \n\u001b[1;32m   2108\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;124;03m    all information about the started training job.\u001b[39;00m\n\u001b[1;32m   2128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2129\u001b[0m train_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_args(estimator, inputs, experiment_config)\n\u001b[0;32m-> 2131\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(estimator\u001b[38;5;241m.\u001b[39msagemaker_session, estimator\u001b[38;5;241m.\u001b[39m_current_job_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:859\u001b[0m, in \u001b[0;36mSession.train\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, training_image_config, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    856\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_training_job(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest)\n\u001b[0;32m--> 859\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5239\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   5222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   5223\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5224\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5227\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   5228\u001b[0m ):\n\u001b[1;32m   5229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   5230\u001b[0m \n\u001b[1;32m   5231\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5237\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   5238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:857\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    855\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating training-job with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[1;32m    856\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m--> 857\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_training_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/local/local_session.py:186\u001b[0m, in \u001b[0;36mLocalSagemakerClient.create_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, Environment, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m InputDataConfig \u001b[38;5;241m=\u001b[39m InputDataConfig \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    185\u001b[0m Environment \u001b[38;5;241m=\u001b[39m Environment \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 186\u001b[0m container \u001b[38;5;241m=\u001b[39m \u001b[43m_SageMakerContainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mResourceConfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInstanceType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mResourceConfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInstanceCount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mAlgorithmSpecification\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingImage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m training_job \u001b[38;5;241m=\u001b[39m _LocalTrainingJob(container)\n\u001b[1;32m    193\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/local/image.py:91\u001b[0m, in \u001b[0;36m_SageMakerContainer.__init__\u001b[0;34m(self, instance_type, instance_count, image, sagemaker_session, container_entrypoint, container_arguments)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# check if docker-compose is installed\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m find_executable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocker-compose\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocker-compose\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocal Mode features will not work without docker-compose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor more information on how to install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocker-compose\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, please, see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.docker.com/compose/install/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session \u001b[38;5;241m=\u001b[39m sagemaker_session \u001b[38;5;129;01mor\u001b[39;00m LocalSession()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance_type \u001b[38;5;241m=\u001b[39m instance_type\n",
      "\u001b[0;31mImportError\u001b[0m: 'docker-compose' is not installed. Local Mode features will not work without docker-compose. For more information on how to install 'docker-compose', please, see https://docs.docker.com/compose/install/"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "hyperparameters = {'epochs': 2}\n",
    "\n",
    "cifar10_estimator = PyTorch(entry_point='source_dir/cifar10.py',\n",
    "                            role=role,\n",
    "                            framework_version='1.7.1',\n",
    "                            py_version='py3',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            instance_count=1,\n",
    "                            instance_type=instance_type)\n",
    "\n",
    "cifar10_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a baseline training job on SageMaker\n",
    "\n",
    "Now we run training jobs on SageMaker, starting with our baseline training job.\n",
    "\n",
    "Once again, we create a PyTorch estimator, with a couple key modfications from last time:\n",
    "\n",
    "* `instance_type`: the instance type for training. We set this to `ml.p3.2xlarge` because we are training on SageMaker now. For a list of available instance types, see [the AWS documentation](https://aws.amazon.com/sagemaker/pricing/instance-types).\n",
    "* `metric_definitions`: the metrics (defined above) that we want sent to CloudWatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-pytorch-2023-10-12-13-38-56-260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-10-12 13:38:56 Starting - Starting the training job...\n",
      "2023-10-12 13:39:22 Starting - Preparing the instances for training.........\n",
      "2023-10-12 13:40:41 Downloading - Downloading input data...\n",
      "2023-10-12 13:41:11 Training - Downloading the training image...............\n",
      "2023-10-12 13:43:57 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-12 13:44:26,955 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-12 13:44:26,984 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-12 13:44:26,987 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-12 13:44:27,278 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-pytorch-2023-10-12-13-38-56-260\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-075912829265/cifar10-pytorch-2023-10-12-13-38-56-260/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-075912829265/cifar10-pytorch-2023-10-12-13-38-56-260/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-pytorch-2023-10-12-13-38-56-260\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-075912829265/cifar10-pytorch-2023-10-12-13-38-56-260/source/sourcedir.tar.gz\",\"module_name\":\"cifar10\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 cifar10.py --epochs 10\u001b[0m\n",
      "\u001b[34mCreating Checkpointing directory /opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mDevice Type: cuda\u001b[0m\n",
      "\u001b[34mLoading Cifar10 dataset\u001b[0m\n",
      "\u001b[34mModel loaded\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.619 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.666 algo-1:27 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.667 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.667 algo-1:27 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.668 algo-1:27 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.668 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.821 algo-1:27 INFO hook.py:591] name:conv1.weight count_params:450\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.821 algo-1:27 INFO hook.py:591] name:conv1.bias count_params:6\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.821 algo-1:27 INFO hook.py:591] name:conv2.weight count_params:2400\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:591] name:conv2.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:591] name:fc1.weight count_params:48000\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:591] name:fc1.bias count_params:120\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:591] name:fc2.weight count_params:10080\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:591] name:fc2.bias count_params:84\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:591] name:fc3.weight count_params:840\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:591] name:fc3.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:593] Total Trainable Params: 62006\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.822 algo-1:27 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-10-12 13:44:31.825 algo-1:27 INFO hook.py:488] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34m[1,  2000] loss: 2.186\u001b[0m\n",
      "\u001b[34m[1,  4000] loss: 1.930\u001b[0m\n",
      "\u001b[34m[1,  6000] loss: 1.755\u001b[0m\n",
      "\u001b[34m[1,  8000] loss: 1.578\u001b[0m\n",
      "\u001b[34m[1, 10000] loss: 1.514\u001b[0m\n",
      "\u001b[34m[1, 12000] loss: 1.469\u001b[0m\n",
      "\u001b[34mepoch: 1 - loss: 2.556701898574829\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[2,  2000] loss: 1.397\u001b[0m\n",
      "\u001b[34m[2,  4000] loss: 1.379\u001b[0m\n",
      "\u001b[34m[2,  6000] loss: 1.362\u001b[0m\n",
      "\u001b[34m[2,  8000] loss: 1.324\u001b[0m\n",
      "\u001b[34m[2, 10000] loss: 1.299\u001b[0m\n",
      "\u001b[34m[2, 12000] loss: 1.290\u001b[0m\n",
      "\u001b[34mepoch: 2 - loss: 0.6036171913146973\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[3,  2000] loss: 1.232\u001b[0m\n",
      "\u001b[34m[3,  4000] loss: 1.227\u001b[0m\n",
      "\u001b[34m[3,  6000] loss: 1.215\u001b[0m\n",
      "\u001b[34m[3,  8000] loss: 1.193\u001b[0m\n",
      "\u001b[34m[3, 10000] loss: 1.187\u001b[0m\n",
      "\u001b[34m[3, 12000] loss: 1.201\u001b[0m\n",
      "\u001b[34mepoch: 3 - loss: 1.8008074760437012\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[4,  2000] loss: 1.121\u001b[0m\n",
      "\u001b[34m[4,  4000] loss: 1.114\u001b[0m\n",
      "\u001b[34m[4,  6000] loss: 1.114\u001b[0m\n",
      "\u001b[34m[4,  8000] loss: 1.133\u001b[0m\n",
      "\u001b[34m[4, 10000] loss: 1.132\u001b[0m\n",
      "\u001b[34m[4, 12000] loss: 1.104\u001b[0m\n",
      "\u001b[34mepoch: 4 - loss: 1.404718041419983\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[5,  2000] loss: 1.034\u001b[0m\n",
      "\u001b[34m[5,  4000] loss: 1.036\u001b[0m\n",
      "\u001b[34m[5,  6000] loss: 1.053\u001b[0m\n",
      "\u001b[34m[5,  8000] loss: 1.078\u001b[0m\n",
      "\u001b[34m[5, 10000] loss: 1.060\u001b[0m\n",
      "\u001b[34m[5, 12000] loss: 1.069\u001b[0m\n",
      "\u001b[34mepoch: 5 - loss: 0.20720145106315613\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[6,  2000] loss: 0.976\u001b[0m\n",
      "\u001b[34m[6,  4000] loss: 0.991\u001b[0m\n",
      "\u001b[34m[6,  6000] loss: 0.976\u001b[0m\n",
      "\u001b[34m[6,  8000] loss: 1.010\u001b[0m\n",
      "\u001b[34m[6, 10000] loss: 1.019\u001b[0m\n",
      "\u001b[34m[6, 12000] loss: 1.028\u001b[0m\n",
      "\u001b[34mepoch: 6 - loss: 0.8537622094154358\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[7,  2000] loss: 0.933\u001b[0m\n",
      "\u001b[34m[7,  4000] loss: 0.936\u001b[0m\n",
      "\u001b[34m[7,  6000] loss: 0.941\u001b[0m\n",
      "\u001b[34m[7,  8000] loss: 0.982\u001b[0m\n",
      "\u001b[34m[7, 10000] loss: 0.965\u001b[0m\n",
      "\u001b[34m[7, 12000] loss: 0.963\u001b[0m\n",
      "\u001b[34mepoch: 7 - loss: 1.1964925527572632\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[8,  2000] loss: 0.876\u001b[0m\n",
      "\u001b[34m[8,  4000] loss: 0.901\u001b[0m\n",
      "\u001b[34m[8,  6000] loss: 0.916\u001b[0m\n",
      "\u001b[34m[8,  8000] loss: 0.931\u001b[0m\n",
      "\u001b[34m[8, 10000] loss: 0.934\u001b[0m\n",
      "\u001b[34m[8, 12000] loss: 0.943\u001b[0m\n",
      "\u001b[34mepoch: 8 - loss: 0.9686529636383057\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[9,  2000] loss: 0.825\u001b[0m\n",
      "\u001b[34m[9,  4000] loss: 0.869\u001b[0m\n",
      "\u001b[34m[9,  6000] loss: 0.892\u001b[0m\n",
      "\u001b[34m[9,  8000] loss: 0.893\u001b[0m\n",
      "\u001b[34m[9, 10000] loss: 0.907\u001b[0m\n",
      "\u001b[34m[9, 12000] loss: 0.913\u001b[0m\n",
      "\u001b[34mepoch: 9 - loss: 0.9118540287017822\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[10,  2000] loss: 0.815\u001b[0m\n",
      "\u001b[34m[10,  4000] loss: 0.834\u001b[0m\n",
      "\u001b[34m[10,  6000] loss: 0.830\u001b[0m\n",
      "\u001b[34m[10,  8000] loss: 0.874\u001b[0m\n",
      "\u001b[34m[10, 10000] loss: 0.864\u001b[0m\n",
      "\u001b[34m[10, 12000] loss: 0.898\u001b[0m\n",
      "\u001b[34mepoch: 10 - loss: 0.9658161401748657\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34mFinished Training\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2023-10-12 13:55:25,983 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-10-12 13:56:11 Uploading - Uploading generated training model\n",
      "2023-10-12 13:56:11 Completed - Training job completed\n",
      "Training seconds: 930\n",
      "Billable seconds: 930\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "hyperparameters = {'epochs': 10}\n",
    "\n",
    "cifar10_estimator = PyTorch(entry_point='source_dir/cifar10.py',\n",
    "                            role=role,\n",
    "                            framework_version='1.7.1',\n",
    "                            py_version='py3',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            instance_count=1,\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            base_job_name='cifar10-pytorch')\n",
    "\n",
    "cifar10_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managed Spot Training with a PyTorch Estimator\n",
    "\n",
    "For Managed Spot Training using a PyTorch Estimator we need to configure two things:\n",
    "1. Enable the `train_use_spot_instances` constructor arg - a simple self-explanatory boolean.\n",
    "2. Set the `train_max_wait` constructor arg - this is an int arg representing the amount of time you are willing to wait for Spot infrastructure to become available. Some instance types are harder to get at Spot prices and you may have to wait longer. You are not charged for time spent waiting for Spot infrastructure to become available, you're only charged for actual compute time spent once Spot instances have been successfully procured.\n",
    "\n",
    "Normally, a third requirement would also be necessary here - modifying your code to ensure a regular checkpointing cadence - however, PyTorch Estimators already do this, so no changes are necessary here. Checkpointing is highly recommended for Manage Spot Training jobs due to the fact that Spot instances can be interrupted with short notice and using checkpoints to resume from the last interruption ensures you don't lose any progress made before the interruption.\n",
    "\n",
    "Feel free to toggle the `use_spot_instances` variable to see the effect of running the same job using regular (a.k.a. \"On Demand\") infrastructure.\n",
    "\n",
    "Note that `max_wait` can be set if and only if `use_spot_instances` is enabled and **must** be greater than or equal to `max_run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_spot_instances = True\n",
    "max_run=600\n",
    "max_wait = 1200 if use_spot_instances else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Spot interruption after 5 epochs\n",
    "\n",
    "Our training job should run on 10 epochs.\n",
    "\n",
    "However, we will simulate a situation that after 5 epochs a spot interruption occurred.\n",
    "\n",
    "The goal is that the checkpointing data will be copied to S3, so when there is a spot capacity available again, the training job can resume from the 6th epoch.\n",
    "\n",
    "Note the `checkpoint_s3_uri` variable which stores the S3 URI in which to persist checkpoints that the algorithm persists (if any) during training.\n",
    "\n",
    "The `debugger_hook_config` parameter must be set to `False` to enable checkpoints to be copied to S3 successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-pytorch-spot-1-2023-10-12-13-57-18-935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-10-12 13:57:19 Starting - Starting the training job...\n",
      "2023-10-12 13:57:45 Starting - Preparing the instances for training............\n",
      "2023-10-12 13:59:49 Downloading - Downloading input data...\n",
      "2023-10-12 14:00:19 Training - Downloading the training image..................\n",
      "2023-10-12 14:03:10 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-12 14:03:36,140 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-12 14:03:36,171 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-12 14:03:36,174 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-12 14:03:36,430 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-pytorch-spot-1-2023-10-12-13-57-18-935\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-075912829265/cifar10-pytorch-spot-1-2023-10-12-13-57-18-935/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":5}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-075912829265/cifar10-pytorch-spot-1-2023-10-12-13-57-18-935/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-pytorch-spot-1-2023-10-12-13-57-18-935\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-075912829265/cifar10-pytorch-spot-1-2023-10-12-13-57-18-935/source/sourcedir.tar.gz\",\"module_name\":\"cifar10\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 cifar10.py --epochs 5\u001b[0m\n",
      "\u001b[34mCheckpointing directory /opt/ml/checkpoints exists\u001b[0m\n",
      "\u001b[34mDevice Type: cuda\u001b[0m\n",
      "\u001b[34mLoading Cifar10 dataset\u001b[0m\n",
      "\u001b[34mModel loaded\u001b[0m\n",
      "\u001b[34m[2023-10-12 14:03:40.883 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-12 14:03:40.931 algo-1:27 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,  2000] loss: 2.209\u001b[0m\n",
      "\u001b[34m[1,  4000] loss: 1.897\u001b[0m\n",
      "\u001b[34m[1,  6000] loss: 1.675\u001b[0m\n",
      "\u001b[34m[1,  8000] loss: 1.590\u001b[0m\n",
      "\u001b[34m[1, 10000] loss: 1.552\u001b[0m\n",
      "\u001b[34m[1, 12000] loss: 1.498\u001b[0m\n",
      "\u001b[34mepoch: 1 - loss: 1.6187008619308472\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[2,  2000] loss: 1.434\u001b[0m\n",
      "\u001b[34m[2,  4000] loss: 1.419\u001b[0m\n",
      "\u001b[34m[2,  6000] loss: 1.382\u001b[0m\n",
      "\u001b[34m[2,  8000] loss: 1.372\u001b[0m\n",
      "\u001b[34m[2, 10000] loss: 1.336\u001b[0m\n",
      "\u001b[34m[2, 12000] loss: 1.311\u001b[0m\n",
      "\u001b[34mepoch: 2 - loss: 0.9007070660591125\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[3,  2000] loss: 1.247\u001b[0m\n",
      "\u001b[34m[3,  4000] loss: 1.244\u001b[0m\n",
      "\u001b[34m[3,  6000] loss: 1.242\u001b[0m\n",
      "\u001b[34m[3,  8000] loss: 1.224\u001b[0m\n",
      "\u001b[34m[3, 10000] loss: 1.221\u001b[0m\n",
      "\u001b[34m[3, 12000] loss: 1.202\u001b[0m\n",
      "\u001b[34mepoch: 3 - loss: 1.6299803256988525\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[4,  2000] loss: 1.120\u001b[0m\n",
      "\u001b[34m[4,  4000] loss: 1.145\u001b[0m\n",
      "\u001b[34m[4,  6000] loss: 1.149\u001b[0m\n",
      "\u001b[34m[4,  8000] loss: 1.141\u001b[0m\n",
      "\u001b[34m[4, 10000] loss: 1.128\u001b[0m\n",
      "\u001b[34m[4, 12000] loss: 1.143\u001b[0m\n",
      "\u001b[34mepoch: 4 - loss: 1.6731128692626953\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[5,  2000] loss: 1.060\u001b[0m\n",
      "\u001b[34m[5,  4000] loss: 1.031\u001b[0m\n",
      "\u001b[34m[5,  6000] loss: 1.061\u001b[0m\n",
      "\u001b[34m[5,  8000] loss: 1.086\u001b[0m\n",
      "\u001b[34m[5, 10000] loss: 1.064\u001b[0m\n",
      "\u001b[34m[5, 12000] loss: 1.048\u001b[0m\n",
      "\u001b[34mepoch: 5 - loss: 1.3302549123764038\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34mFinished Training\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2023-10-12 14:09:08,502 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-10-12 14:09:23 Uploading - Uploading generated training model\n",
      "2023-10-12 14:09:23 Completed - Training job completed\n",
      "Training seconds: 574\n",
      "Billable seconds: 190\n",
      "Managed Spot Training savings: 66.9%\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {'epochs': 5}\n",
    "\n",
    "\n",
    "spot_estimator = PyTorch(entry_point='source_dir/cifar10.py',\n",
    "                            role=role,\n",
    "                            framework_version='1.7.1',\n",
    "                            py_version='py3',\n",
    "                            instance_count=1,\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            base_job_name='cifar10-pytorch-spot-1',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            checkpoint_s3_uri=checkpoint_s3_path,\n",
    "                            debugger_hook_config=False,\n",
    "                            use_spot_instances=use_spot_instances,\n",
    "                            max_run=max_run,\n",
    "                            max_wait=max_wait)\n",
    "\n",
    "spot_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savings\n",
    "Towards the end of the job you should see two lines of output printed:\n",
    "\n",
    "- `Training seconds: X` : This is the actual compute-time your training job spent\n",
    "- `Billable seconds: Y` : This is the time you will be billed for after Spot discounting is applied.\n",
    "\n",
    "If you enabled the `use_spot_instances` var then you should see a notable difference between `X` and `Y` signifying the cost savings you will get for having chosen Managed Spot Training. This should be reflected in an additional line:\n",
    "- `Managed Spot Training savings: (1-Y/X)*100 %`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the job training Checkpoint configuration\n",
    "We can now view the Checkpoint configuration from the training job directly in the SageMaker console.\n",
    "\n",
    "Log into the [SageMaker console](https://console.aws.amazon.com/sagemaker/home), choose the latest training job, and scroll down to the Checkpoint configuration section. \n",
    "\n",
    "Choose the S3 output path link and you'll be directed to the S3 bucket were checkpointing data is saved.\n",
    "\n",
    "You can see there is one file there:\n",
    "\n",
    "```python\n",
    "checkpoint.pth\n",
    "```\n",
    "\n",
    "This is the checkpoint file that contains the epoch, model state dict, optimizer state dict, and loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue training after Spot capacity is resumed\n",
    "\n",
    "Now we simulate a situation where Spot capacity is resumed.\n",
    "\n",
    "We will start a training job again, this time with 10 epochs.\n",
    "\n",
    "What we expect is that the tarining job will start from the 6th epoch.\n",
    "\n",
    "This is done when training job starts. It checks the checkpoint s3 location for checkpoints data. If there are, they are copied to `/opt/ml/checkpoints` on the training conatiner.\n",
    "\n",
    "In the code you can see the function to load the checkpoints data:\n",
    "\n",
    "```python\n",
    "def _load_checkpoint(model, optimizer, args):\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Checkpoint file found!\")\n",
    "    print(\"Loading Checkpoint From: {}\".format(args.checkpoint_path + '/checkpoint.pth'))\n",
    "    checkpoint = torch.load(args.checkpoint_path + '/checkpoint.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch_number = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(\"Checkpoint File Loaded - epoch_number: {} - loss: {}\".format(epoch_number, loss))\n",
    "    print('Resuming training from epoch: {}'.format(epoch_number+1))\n",
    "    print(\"--------------------------------------------\")\n",
    "    return model, optimizer, epoch_number\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 10}\n",
    "\n",
    "\n",
    "spot_estimator = PyTorch(entry_point='source_dir/cifar10.py',\n",
    "                            role=role,\n",
    "                            framework_version='1.7.1',\n",
    "                            py_version='py3',\n",
    "                            instance_count=1,\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            base_job_name='cifar10-pytorch-spot-2',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            checkpoint_s3_uri=checkpoint_s3_path,\n",
    "                            debugger_hook_config=False,\n",
    "                            use_spot_instances=use_spot_instances,\n",
    "                            max_run=max_run,\n",
    "                            max_wait=max_wait)\n",
    "\n",
    "spot_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze training job logs\n",
    "\n",
    "Analyzing the training job logs, we can see that now, the training job starts from the 6th epoch.\n",
    "\n",
    "We can see the output of `_load_checkpoint` function:\n",
    "\n",
    "```\n",
    "--------------------------------------------\n",
    "Checkpoint file found!\n",
    "Loading Checkpoint From: /opt/ml/checkpoints/checkpoint.pth\n",
    "Checkpoint File Loaded - epoch_number: 5 - loss: 0.8455273509025574\n",
    "Resuming training from epoch: 6\n",
    "--------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the job training Checkpoint configuration after job completed 10 epochs\n",
    "\n",
    "We can now view the Checkpoint configuration from the training job directly in the SageMaker console.  \n",
    "\n",
    "Log into the [SageMaker console](https://console.aws.amazon.com/sagemaker/home), choose the latest training job, and scroll down to the Checkpoint configuration section. \n",
    "\n",
    "Choose the S3 output path link and you'll be directed to the S3 bucket were checkpointing data is saved.\n",
    "\n",
    "You can see there is still that one file there:\n",
    "\n",
    "```python\n",
    "checkpoint.pth\n",
    "```\n",
    "\n",
    "You'll be able to see that the date of the checkpoint file was updated to the time of the 2nd Spot training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "predictor = spot_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some test images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%4s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = predictor.predict(images.numpy())\n",
    "\n",
    "_, predicted = torch.max(torch.from_numpy(np.array(outputs)), 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%4s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "To avoid incurring extra charges to your AWS account, let's delete the endpoint we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
